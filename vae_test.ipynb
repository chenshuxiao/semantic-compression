{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from vae import VAE\n",
    "from losses import loss_function, BetaSchedulerCyclic, BetaSchedulerMono\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "from itertools import islice\n",
    "from blocks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResStage(\n",
      "  (b1): ResBlock(\n",
      "    (f): BasicTransform(\n",
      "      (a): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (a_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (a_relu): ReLU(inplace=True)\n",
      "      (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (b_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'HAS_BN': True,\n",
    "    'SReLU': False,\n",
    "    'HAS_ST': False,\n",
    "    'DROPOUT': 0,\n",
    "    'CIFAR': True,\n",
    "    'DIRAC_INIT': False\n",
    "}\n",
    "# a = ResStem(w_in=3, w_out=64, **kwargs)\n",
    "# print (kwargs['HAS_BN'])\n",
    "a = ResStage(w_in=64, w_out=64, stride=2, d=1, **kwargs)\n",
    "print (a)\n",
    "# for m in a.modules():\n",
    "#     if m i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256, 512]\n",
      "[1, 1, 1, 1]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): ResStem(\n",
       "      (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): SReLU(\n",
       "        (srelu_relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (a_relu): SReLU(\n",
       "            (srelu_relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (relu): SReLU(\n",
       "          (srelu_relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (a_relu): SReLU(\n",
       "            (srelu_relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (relu): SReLU(\n",
       "          (srelu_relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (a_relu): SReLU(\n",
       "            (srelu_relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (relu): SReLU(\n",
       "          (srelu_relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (a_relu): SReLU(\n",
       "            (srelu_relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (relu): SReLU(\n",
       "          (srelu_relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=8192, out_features=20, bias=True)\n",
       "  (fc_var): Linear(in_features=8192, out_features=20, bias=True)\n",
       "  (decoder_input): Linear(in_features=20, out_features=8192, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (a_relu): ReLU(inplace=True)\n",
       "          (b): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PixelShuffle(upscale_factor=2)\n",
       "    (2): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (a_relu): ReLU(inplace=True)\n",
       "          (b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PixelShuffle(upscale_factor=2)\n",
       "    (4): ResStage(\n",
       "      (b1): ResBlock(\n",
       "        (proj): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (f): BasicTransform(\n",
       "          (a): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (a_relu): ReLU(inplace=True)\n",
       "          (b): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): PixelShuffle(upscale_factor=2)\n",
       "    (6): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'HAS_BN': True,\n",
    "    'SReLU': False,\n",
    "    'HAS_ST': False,\n",
    "    'DROPOUT': 0,\n",
    "    'CIFAR': True,\n",
    "    'DIRAC_INIT': False\n",
    "}\n",
    "kwargs_resnet_enc = {\n",
    "    'HAS_BN': False,\n",
    "    'SReLU': True,\n",
    "    'HAS_ST': True,\n",
    "    'DROPOUT': 0,\n",
    "    'CIFAR': True,\n",
    "    'DIRAC_INIT': True\n",
    "}\n",
    "kwargs_resnet_dec = {\n",
    "    'HAS_BN': False,\n",
    "    'SReLU': False,\n",
    "    'HAS_ST': True,\n",
    "    'DROPOUT': 0,\n",
    "    'CIFAR': True,\n",
    "    'DIRAC_INIT': False\n",
    "}\n",
    "z_size = 20\n",
    "in_channels = 1\n",
    "vae = VAE(in_channels=in_channels, latent_dim=z_size, res=32, stage_count=4, layer_mult=64, d=1,\n",
    "          kwargs_enc=kwargs_resnet_enc, kwargs_dec=kwargs_resnet_dec)\n",
    "vae.cuda()\n",
    "vae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "# torchvision.transforms.Normalize(\n",
    "#  (0.1307,), (0.3081,))\n",
    "slen = 32\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((slen,slen)),\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((slen,slen)),\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 32, 32])\n",
      "torch.Size([256])\n",
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "examples = list(test_loader)\n",
    "print (examples[0][0].shape)\n",
    "print (examples[0][1].shape)\n",
    "print (examples[0][0][0].shape)\n",
    "\n",
    "# plt.imshow (examples[0][0][0].view(slen,slen))\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# print (torch.mean(examples[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vae.encoder(examples[0][0][0].view(1,1,slen,slen).cuda())\n",
    "results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vae(examples[0][0][0].view(1,1,slen,slen).cuda())\n",
    "results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = torch.randn(64, z_size).view(-1, z_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8192])\n",
      "torch.Size([64, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "a = vae.decoder_input(sample1)\n",
    "print (a.shape)\n",
    "a = a.view(sample1.shape[0], vae.last_hdim, vae.code_len, vae.code_len)\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "a = vae.decoder(a)\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = BetaSchedulerMono()\n",
    "\n",
    "# x = list(islice(a, 0, 4000))\n",
    "# plt.plot(x)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:58<48:04, 58.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/50] recon: 0.024486740, KL: 0.011219303, enc: 0.000000000, dec: 0.000000000\n",
      "\n",
      "[2/50] recon: 0.026886469, KL: 0.013998934, enc: 0.000000000, dec: 0.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [01:56<46:47, 58.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/50] recon: nan, KL: nan, enc: 0.000000000, dec: 0.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [03:08<49:12, 62.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ec995669a3f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mloss_re\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mvae_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mre_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mkl_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_kl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#         en_loss += loss_enc.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name='iso_mnist_'+time.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "os.makedirs(name, exist_ok=True)\n",
    "recon_dir = os.path.join (name,'results_recon')\n",
    "os.makedirs(recon_dir, exist_ok=True)\n",
    "gen_dir = os.path.join (name,'results_gen')\n",
    "os.makedirs(gen_dir, exist_ok=True)\n",
    "\n",
    "lr = 0.0005\n",
    "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "train_epoch = 50\n",
    "\n",
    "re_loss_arr = []\n",
    "kl_loss_arr = []\n",
    "\n",
    "# for decode testing, batch size of 64\n",
    "sample1 = torch.randn(64, z_size).view(-1, z_size).cuda()\n",
    "beta_iter = BetaSchedulerCyclic(stop=.002, period=len(train_loader)*2)\n",
    "\n",
    "for epoch in tqdm(range(train_epoch)):\n",
    "    \n",
    "    re_loss = 0\n",
    "    kl_loss = 0\n",
    "    en_loss = 0\n",
    "    de_loss = 0\n",
    "    \n",
    "    for x in train_loader:\n",
    "        x = x[0].cuda()\n",
    "        vae.zero_grad()\n",
    "#         print (x.shape)\n",
    "        recon, mu, logvar = vae(x)\n",
    "#         print (recon.shape)\n",
    "        loss = loss_function(recon, x, mu, logvar, kld_weight=next(beta_iter),\n",
    "                             enc_ortho_coeff=0, dec_ortho_coeff=0)\n",
    "        loss_re, loss_kl= loss['recon'], loss['KLD']\n",
    "#         loss_enc, loss_dec \n",
    "#         loss['enc_ortho'], loss['dec_ortho']\n",
    "        (loss_re + loss_kl).backward()\n",
    "        vae_optimizer.step()\n",
    "        re_loss += loss_re.item()\n",
    "        kl_loss += loss_kl.item()\n",
    "#         en_loss += loss_enc.item()\n",
    "#         de_loss += loss_dec.item()\n",
    "\n",
    "    re_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    en_loss /= len(train_loader)\n",
    "    de_loss /= len(train_loader)\n",
    "    print('\\n[%d/%d] recon: %.9f, KL: %.9f, enc: %.9f, dec: %.9f' % (\n",
    "        (epoch + 1), train_epoch, re_loss, kl_loss, en_loss, de_loss))\n",
    "    re_loss_arr.append(re_loss)\n",
    "    kl_loss_arr.append(kl_loss)\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            vae.eval()\n",
    "            x_rec, _, _ = vae(x)\n",
    "            resultsample = torch.cat([x, x_rec]) #unstandardization: * 0.3081 + 0.1307\n",
    "            resultsample = resultsample.cpu()\n",
    "            save_image(resultsample.view(-1, in_channels, slen*2, slen),\n",
    "                       recon_dir + '/' + str(epoch) + '.png')\n",
    "            x_rec = vae.decode(sample1)\n",
    "#             resultsample = x_rec * 0.3081 + 0.1307\n",
    "            resultsample = x_rec.cpu()\n",
    "            save_image(resultsample.view(-1, in_channels, slen, slen),\n",
    "                       gen_dir + '/' + str(epoch) + '.png')\n",
    "        vae.train()\n",
    "        \n",
    "    # checkpoint\n",
    "    torch.save(vae.state_dict(), name + \"/VAEmodel.pkl\")\n",
    "    \n",
    "print(\"Training finish!... save training results\")\n",
    "torch.save(vae.state_dict(), \"VAEmodel.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss_arr[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(re_loss_arr[3:], label='recon loss')\n",
    "plt.plot(kl_loss_arr[3:], label='kl loss')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISONet.isonet.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iso:\n",
    "\n",
    "[1/50] recon: 0.485941466, KL: 0.044795726, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "[2/50] recon: 0.371852721, KL: 0.059582863, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "\n",
    "devel:\n",
    "\n",
    "[1/50] recon loss: 0.255265573, KL loss: 0.118971909\n",
    "\n",
    "[2/50] recon loss: 0.164801195, KL loss: 0.114278781\n",
    "\n",
    "\n",
    "The difference is due to tanh. Why?\n",
    "Should not have standardize\n",
    "\n",
    "also for some reason init_coder makes kl loss very low and recon very hi,\n",
    "for some reason prioritizes kl divergence\n",
    "please investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[1/50] recon: 0.071641286, KL: 0.000074601, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "[2/50] recon: 0.059202360, KL: 0.000047522, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "  4%|▍         | 2/50 [01:45<42:10, 52.72s/it]\n",
    "\n",
    "\n",
    "[3/50] recon: 0.060000994, KL: 0.000026837, enc: 0.000000000, dec: 0.000000000\n",
    "^bn on decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[1/50] recon: 0.069124465, KL: 0.035863264, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "[2/50] recon: 0.058032005, KL: 29.810605342, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "  4%|▍         | 2/50 [01:45<42:23, 53.00s/it]\n",
    "\n",
    "\n",
    "[3/50] recon: 0.055112885, KL: 5484343.761168436, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "  6%|▌         | 3/50 [02:38<41:29, 52.96s/it]\n",
    "\n",
    "\n",
    "[4/50] recon: 0.054966730, KL: 0.034717195, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    "  8%|▊         | 4/50 [03:30<40:27, 52.78s/it]\n",
    "\n",
    "\n",
    "[5/50] recon: 0.054664997, KL: 0.015396994, enc: 0.000000000, dec: 0.000000000\n",
    "\n",
    " 10%|█         | 5/50 [04:23<39:28, 52.64s/it]\n",
    "\n",
    "\n",
    "[6/50] recon: 0.054381395, KL: 0.062738713, enc: 0.000000000, dec: 0.000000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon suddenly spikes and kl drops: reason is not due to cyclic\n",
    "it seems there is an ez way to get really low kl and ok recon by just spreading everything uniform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (isonet)",
   "language": "python",
   "name": "isonet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

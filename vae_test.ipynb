{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from vae import VanillaVAE\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=4096, out_features=64, bias=True)\n",
       "  (fc_var): Linear(in_features=4096, out_features=64, bias=True)\n",
       "  (decoder_input): Linear(in_features=64, out_features=4096, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_size = 64\n",
    "in_channels = 1\n",
    "vae = VanillaVAE(in_channels=in_channels, latent_dim=z_size, res=32, layer_count=2)\n",
    "vae.cuda()\n",
    "vae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slen = 32\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((slen,slen)),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.Resize((slen,slen)),\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 40\n"
     ]
    }
   ],
   "source": [
    "print (len (train_loader), len (test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 32, 32])\n",
      "torch.Size([256])\n",
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0395)\n"
     ]
    }
   ],
   "source": [
    "examples = list(test_loader)\n",
    "print (examples[0][0].shape)\n",
    "print (examples[0][1].shape)\n",
    "print (examples[0][0][0].shape)\n",
    "\n",
    "plt.imshow (examples[0][0][0].view(slen,slen))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print (torch.mean(examples[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vae.encoder(examples[0][0][0].view(1,1,slen,slen).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mnist_12-02-2020_04-16-03\n"
     ]
    }
   ],
   "source": [
    "name='test'+'_mnist_'+time.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:15<12:38, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/50] recon loss: 0.327086901, KL loss: 0.055862329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:30<12:22, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/50] recon loss: 0.296351105, KL loss: 0.048524085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:46<12:07, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/50] recon loss: 0.292746197, KL loss: 0.046400644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [01:01<11:52, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/50] recon loss: 0.290824422, KL loss: 0.045411188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [01:17<11:36, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/50] recon loss: 0.289694829, KL loss: 0.044696115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [01:32<11:21, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/50] recon loss: 0.288748044, KL loss: 0.044155345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [01:48<11:06, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/50] recon loss: 0.288225808, KL loss: 0.043671022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [02:04<10:52, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/50] recon loss: 0.287628928, KL loss: 0.043337664\n"
     ]
    }
   ],
   "source": [
    "name='test_mnist_'+time.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "os.makedirs(name, exist_ok=True)\n",
    "recon_dir = os.path.join (name,'results_recon')\n",
    "os.makedirs(recon_dir, exist_ok=True)\n",
    "gen_dir = os.path.join (name,'results_gen')\n",
    "os.makedirs(gen_dir, exist_ok=True)\n",
    "\n",
    "lr = 0.0005\n",
    "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "train_epoch = 50\n",
    "\n",
    "re_loss_arr = []\n",
    "kl_loss_arr = []\n",
    "\n",
    "# for decode testing, batch size of 64\n",
    "sample1 = torch.randn(64, z_size).view(-1, z_size).cuda()\n",
    "\n",
    "for epoch in tqdm(range(train_epoch)):\n",
    "    \n",
    "    re_loss = 0\n",
    "    kl_loss = 0\n",
    "    \n",
    "    for x in train_loader:\n",
    "        x = x[0].cuda()\n",
    "        vae.zero_grad()\n",
    "#         print (x.shape)\n",
    "        recon, mu, logvar = vae(x)\n",
    "#         print (recon.shape)\n",
    "        loss = vae.loss_function(recon, x, mu, logvar, kld_weight=0.1)\n",
    "        loss_re, loss_kl = loss['reconstruction_loss'], loss['KLD']\n",
    "        (loss_re + loss_kl).backward()\n",
    "        vae_optimizer.step()\n",
    "        re_loss += loss_re.detach().item()\n",
    "        kl_loss += loss_kl.detach().item()\n",
    "\n",
    "    re_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    print('\\n[%d/%d] recon loss: %.9f, KL loss: %.9f' % (\n",
    "        (epoch + 1), train_epoch, re_loss, kl_loss))\n",
    "    re_loss_arr.append(re_loss)\n",
    "    kl_loss_arr.append(kl_loss)\n",
    "    if epoch % 2 == 0:\n",
    "        with torch.no_grad():\n",
    "            vae.eval()\n",
    "            x_rec, _, _ = vae(x)\n",
    "            resultsample = torch.cat([x, x_rec]) * 0.3081 + 0.1307\n",
    "            resultsample = resultsample.cpu()\n",
    "            save_image(resultsample.view(-1, in_channels, slen*2, slen),\n",
    "                       recon_dir + '/' + str(epoch) + '.png')\n",
    "            x_rec = vae.decode(sample1)\n",
    "            resultsample = x_rec * 0.3081 + 0.1307\n",
    "            resultsample = resultsample.cpu()\n",
    "            save_image(resultsample.view(-1, in_channels, slen, slen),\n",
    "                       gen_dir + '/' + str(epoch) + '.png')\n",
    "        vae.train()\n",
    "        \n",
    "    # checkpoint\n",
    "    torch.save(vae.state_dict(), name + \"/VAEmodel.pkl\")\n",
    "    \n",
    "print(\"Training finish!... save training results\")\n",
    "torch.save(vae.state_dict(), \"VAEmodel.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (isonet)",
   "language": "python",
   "name": "isonet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
